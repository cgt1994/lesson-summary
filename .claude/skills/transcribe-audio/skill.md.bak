# Transcribe Audio to Text

Convert audio files (MP3, MP4, WAV, M4A, etc.) to text using OpenAI's Whisper model.

## Prerequisites

Whisper must be installed on the system:

```bash
# Check if whisper is installed
which whisper || echo "Whisper not found. Please install it first."
```

### Install Whisper

```bash
pip install -U openai-whisper
```

**Note:** Whisper requires FFmpeg to be installed as well.

## How to use this skill

Transcribe a single audio file:

```bash
whisper "$1" --model base --language zh --output_format txt --output_dir "${2:-.}"
```

## Whisper parameters explained

- `$1` - Input audio file (required argument)
- `--model base` - Model size (tiny, base, small, medium, large)
- `--language zh` - Source language (auto-detect if not specified)
- `--output_format txt` - Output format (txt, srt, vtt, json, tsv)
- `--output_dir` - Output directory (defaults to current directory)

## Available models

- **tiny** - Fastest, lowest accuracy (~1GB RAM)
- **base** - Fast, good for testing (~1GB RAM)
- **small** - Good balance (~2GB RAM)
- **medium** - High accuracy (~5GB RAM)
- **large** - Best accuracy, slowest (~10GB RAM)

## Examples

Basic transcription (auto-detect language):
```
/transcribe-audio lesson-audio.mp3
```

Specify Chinese language:
```
/transcribe-audio lesson-audio.mp3 --language zh
```

Use higher accuracy model:
```
/transcribe-audio lesson-audio.mp3 --model medium
```

Custom output directory:
```
/transcribe-audio lesson-audio.mp3 --output-dir ./transcripts
```

Generate SRT subtitles:
```
/transcribe-audio lesson-audio.mp3 --format srt
```

## Language codes

Common language codes:
- `zh` - Chinese
- `en` - English
- `ja` - Japanese
- `ko` - Korean
- `es` - Spanish
- `fr` - French
- Leave empty for auto-detection

## Output formats

- **txt** - Plain text transcript (default)
- **srt** - SubRip subtitle format
- **vtt** - WebVTT subtitle format
- **json** - Detailed JSON with timestamps
- **tsv** - Tab-separated values

## What to display

After transcription completes, show:
- Input file name and duration
- Output file name and location
- Model used
- Language detected/specified
- Processing time
- Success/error message

Example output:
```
✓ Transcription completed!

Input:  lesson-audio.mp3 (2:11)
Output: lesson-audio.txt
Model:  base
Language: Chinese (zh)
Time:   45.3 seconds
Location: /Users/ethan/Downloads/lesson-audio.txt
```

## Error handling

Common issues:

- **"whisper: command not found"**: Whisper not installed
- **"No such file or directory"**: Check input file path
- **"Out of memory"**: Try a smaller model (tiny or base)
- **"FFmpeg not found"**: Install FFmpeg first

## Batch transcription

If user wants to transcribe multiple files:

```bash
for file in *.mp3; do
  whisper "$file" --model base --language zh --output_format txt
done
```

## Advanced options

**Transcribe specific segment:**
```bash
# First extract segment with FFmpeg, then transcribe
ffmpeg -i input.mp3 -ss 00:01:30 -to 00:05:00 segment.mp3
whisper segment.mp3 --model base
```

**Better accuracy for Chinese:**
```bash
whisper input.mp3 --model medium --language zh --initial_prompt "这是一段中文音频"
```

**Multiple output formats:**
```bash
whisper input.mp3 --model base --output_format txt --output_format srt
```

## Tips for best results

1. Use `medium` or `large` model for important transcriptions
2. Specify `--language` for faster processing and better accuracy
3. Ensure audio is clear (low background noise)
4. For long files, consider using `--device cuda` if GPU available
5. Use `--initial_prompt` to provide context for better accuracy
